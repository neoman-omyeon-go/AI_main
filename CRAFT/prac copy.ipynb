{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "source": [
    "from PIL import Image, ImageDraw\n",
    "\n",
    "# Load the image\n",
    "image_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.jpg'\n",
    "# image_path = './data/res_더 단백 커피.jpg'\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Reset the image to remove previous drawings\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Create a new draw object since we reset the image\n",
    "draw = ImageDraw.Draw(image)\n",
    "\n",
    "# Now let's try to draw rectangles using the coordinates assuming they represent two opposite corners of rectangles\n",
    "# The expected format is: x1, y1, x2, y1, x2, y2, x1, y2\n",
    "\n",
    "# Let's open the text file and read its contents to understand the format\n",
    "\n",
    "text_file_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.txt'\n",
    "# with open(text_file_path, 'r') as file:\n",
    "#     boxes = file.readlines()\n",
    "with open(text_file_path, 'r') as file:\n",
    "    text_file_contents = file.read()\n",
    "\n",
    "text_file_contents\n",
    "\n",
    "\n",
    "def draw_rectangles_from_corners(draw, coordinates):\n",
    "    for line in coordinates.split('\\n'):\n",
    "        if line:\n",
    "            # Split the line into pairs of coordinates (x,y)\n",
    "            points = [int(n) for n in line.split(',')]\n",
    "            # Use only the first and the third pair as the coordinates for the top left and bottom right corners\n",
    "            draw.rectangle([points[0], points[1], points[4], points[5]], outline=\"red\", width=2)\n",
    "\n",
    "# Draw the rectangles using the coordinates from the text file\n",
    "draw_rectangles_from_corners(draw, text_file_contents)\n",
    "\n",
    "# Save the image with the rectangles drawn\n",
    "corrected_annotated_image_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/corrected_annotated_image.jpg'\n",
    "image.save(corrected_annotated_image_path)\n",
    "\n",
    "corrected_annotated_image_path\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "source": [
    "# Since the previous cells have been cleared, we need to redefine `text_file_contents`.\n",
    "# Let's reopen the text file and read its contents to redefine the variable.\n",
    "with open(text_file_path, 'r') as file:\n",
    "    text_file_contents = file.read()\n",
    "\n",
    "# Confirming the contents are correctly loaded\n",
    "text_file_contents[:500]  # Displaying first 100 characters for brevity\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "source": [
    "# 440 len\n",
    "\n",
    "# li = [173,44,229,44,229,74,173,74,\n",
    "# 225,45,254,45,254,70,225,70,\n",
    "# 253,48,274,48,274,70,253,70,\n",
    "# 34,46,106,46,106,90,34,90,\n",
    "# 202,74,240,74,240,109,202,109,\n",
    "# 237,76,277,76,277,109,237,109,\n",
    "# 142,114,186,114,186,141,142,141,\n",
    "# 184,114,230,114,230,140,184,140,\n",
    "# 228,114,253,114,253,140,228,140,\n",
    "# 250,114,276,114,276,140,250,140,\n",
    "# 32,117,44,117,44,140,32,140,\n",
    "# 42,116,86,116,86,141,42,141,\n",
    "# 124,117,144,117,144,141,124,141,\n",
    "# 33,148,84,148,84,180,33,180,\n",
    "# 144,149,193,149,193,177,144,177,\n",
    "# 240,150,252,150,252,173,240,173,\n",
    "# 253,150,272,150,272,176,253,176,\n",
    "# 33,186,101,186,101,220,33,220,\n",
    "# 237,188,272,188,272,216,237,216,\n",
    "# 166,189,193,189,193,218,166,218,\n",
    "# 42,225,77,225,77,260,42,260,\n",
    "# 153,228,193,228,193,260,153,260,\n",
    "# 237,228,270,228,270,254,237,254,\n",
    "# 42,264,125,264,125,297,42,297,\n",
    "# 154,266,193,266,193,297,154,297,\n",
    "# 33,302,70,302,70,334,33,334,\n",
    "# 236,305,269,305,269,332,236,332,\n",
    "# 169,308,193,308,193,336,169,336,\n",
    "# 44,341,126,341,126,373,44,373,\n",
    "# 165,344,193,344,193,374,165,374,\n",
    "# 42,378,110,378,110,412,42,412,\n",
    "# 153,382,193,382,193,412,153,412,\n",
    "# 236,382,269,382,269,409,236,409,\n",
    "# 36,417,115,417,115,449,36,449,\n",
    "# 145,416,195,424,191,452,141,444,\n",
    "# 236,420,268,420,268,446,236,446,\n",
    "# 36,454,85,454,85,485,36,485,\n",
    "# 157,457,193,457,193,489,157,489,\n",
    "# 225,457,249,457,249,485,225,485,\n",
    "# 249,458,268,458,268,484,249,484,\n",
    "# 36,492,69,492,69,522,36,522,\n",
    "# 121,494,166,494,166,521,121,521,\n",
    "# 165,500,192,500,192,525,165,525,\n",
    "# 34,528,86,528,86,560,34,560,\n",
    "# 122,532,166,532,166,560,122,560,\n",
    "# 165,537,192,537,192,562,165,562,\n",
    "# 36,565,69,565,69,596,36,596,\n",
    "# 122,569,165,569,165,596,122,596,\n",
    "# 165,573,192,573,192,600,165,600,\n",
    "# 36,602,115,602,115,634,36,634,\n",
    "# 122,606,166,606,166,634,122,634,\n",
    "# 165,610,192,610,192,637,165,637,\n",
    "# 36,640,101,640,101,672,36,672,\n",
    "# 133,642,166,642,166,669,133,669,\n",
    "# 164,646,192,646,192,676,164,676]\n",
    "\n",
    "# print(li.__len__())"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to extract the bounding box information\n",
    "def extract_boxes(text_content):\n",
    "    # Extract lines using regex to match the numerical patterns\n",
    "    return re.findall(r'(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+)', text_content)\n",
    "\n",
    "# Load the image where we want to extract the boxes\n",
    "img_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.jpg'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Read the coordinates from the uploaded .txt file\n",
    "txt_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.txt'\n",
    "with open(txt_path, 'r') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Call the function to extract boxes from the content\n",
    "boxes = extract_boxes(text_content)\n",
    "\n",
    "# Directory to save cropped images\n",
    "save_dir = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/crop_craft/'\n",
    "\n",
    "# Ensure the save directory exists\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize dictionary to store image details\n",
    "images_details = {}\n",
    "\n",
    "# Cropping and saving each image based on the bounding box\n",
    "for idx, box in enumerate(boxes):\n",
    "    x_coords = [int(box[i]) for i in range(0, 8, 2)]\n",
    "    # print('x_coords : ', x_coords)\n",
    "    y_coords = [int(box[i]) for i in range(1, 8, 2)]\n",
    "    # print('y_coords : ', y_coords)\n",
    "    \n",
    "    # Extract the minimum and maximum coordinates\n",
    "    min_x, max_x = min(x_coords), max(x_coords)\n",
    "    min_y, max_y = min(y_coords), max(y_coords)\n",
    "    \n",
    "    # Define width and height of the box\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_img = img[min_y:max_y, min_x:max_x]\n",
    "    \n",
    "    # Define the file name for the cropped image\n",
    "    img_name = f'text_{idx}.jpg'\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cv2.imwrite(save_dir + img_name, cropped_img)\n",
    "    \n",
    "    # Store details in the dictionary\n",
    "    images_details[img_name] = {'x': min_x, 'y': min_y, 'w': width, 'h': height}\n",
    "    \n",
    "# Return the dictionary with image details\n",
    "images_details"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "details_file_name = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/crop_craft/image_details.txt'\n",
    "\n",
    "# Write the details to the .txt file\n",
    "with open(details_file_name, 'w') as file:\n",
    "    for img_name, details in images_details.items():\n",
    "        file.write(f'{img_name}: {details}\\n')\n",
    "\n",
    "# Return the path to the saved .txt file\n",
    "details_file_name"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to extract the bounding box information\n",
    "def extract_boxes(text_content):\n",
    "    # Extract lines using regex to match the numerical patterns\n",
    "    return re.findall(r'(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+)', text_content)\n",
    "\n",
    "# Load the image where we want to extract the boxes\n",
    "# img_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.jpg'\n",
    "img_path = '/home/eslab/osh/CapStone/data/더 단백 커피.png'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Read the coordinates from the uploaded .txt file\n",
    "txt_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.txt'\n",
    "with open(txt_path, 'r') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Call the function to extract boxes from the content\n",
    "boxes = extract_boxes(text_content)\n",
    "\n",
    "# Directory to save cropped images\n",
    "save_dir = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/crop_craft/'\n",
    "\n",
    "# Ensure the save directory exists\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize dictionary to store image details\n",
    "images_details = {}\n",
    "\n",
    "# Cropping and saving each image based on the bounding box\n",
    "for idx, box in enumerate(boxes):\n",
    "    x_coords = [int(box[i]) for i in range(0, 8, 2)]\n",
    "    # print('x_coords : ', x_coords)\n",
    "    y_coords = [int(box[i]) for i in range(1, 8, 2)]\n",
    "    # print('y_coords : ', y_coords)\n",
    "    \n",
    "    # Extract the minimum and maximum coordinates\n",
    "    min_x, max_x = min(x_coords), max(x_coords)\n",
    "    min_y, max_y = min(y_coords), max(y_coords)\n",
    "    \n",
    "    # Define width and height of the box\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_img = img[min_y:max_y, min_x:max_x]\n",
    "    \n",
    "    # Define the file name for the cropped image\n",
    "    img_name = f'text_{idx}.jpg'\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cv2.imwrite(save_dir + img_name, cropped_img)\n",
    "    \n",
    "    # Store details in the dictionary\n",
    "    images_details[img_name] = {'x': min_x, 'y': min_y, 'w': width, 'h': height}\n",
    "    \n",
    "# Return the dictionary with image details\n",
    "images_details"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_boxes(text_content):\n",
    "    return re.findall(r'(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+)', text_content)\n",
    "\n",
    "def process_image(img_path, txt_path, save_dir):\n",
    "    # Load the image\n",
    "    img = cv2.imread(str(img_path))\n",
    "    \n",
    "    # Read the coordinates from the .txt file\n",
    "    with open(txt_path, 'r') as file:\n",
    "        text_content = file.read()\n",
    "    \n",
    "    # Extract boxes from the content\n",
    "    boxes = extract_boxes(text_content)\n",
    "    \n",
    "    images_details = {}\n",
    "    \n",
    "    for idx, box in enumerate(boxes):\n",
    "        x_coords = [int(box[i]) for i in range(0, 8, 2)]\n",
    "        print('x_coords : ', x_coords)\n",
    "        y_coords = [int(box[i]) for i in range(1, 8, 2)]\n",
    "        print('y_coords : ', y_coords)\n",
    "        \n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "        \n",
    "        width = max_x - min_x\n",
    "        height = max_y - min_y\n",
    "        \n",
    "        cropped_img = img[min_y:max_y, min_x:max_x]\n",
    "        img_name = f'text_{idx}.jpg'\n",
    "        \n",
    "        cv2.imwrite(save_dir + img_name, cropped_img)\n",
    "        \n",
    "        images_details[img_name] = {'x': min_x, 'y': min_y, 'w': width, 'h': height}\n",
    "    \n",
    "    return images_details\n",
    "\n",
    "# Directory paths\n",
    "img_dir = Path('/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/')\n",
    "save_dir = Path('/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/crop_craft/')\n",
    "save_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Process each image and its corresponding text file\n",
    "for img_path in img_dir.glob('*.jpg'):\n",
    "    txt_path = img_dir / f'res_{img_path.stem}.txt'\n",
    "    if txt_path.exists():\n",
    "        print(f'Processing {img_path.name}...')\n",
    "        images_details = process_image(img_path, txt_path, str(save_dir))\n",
    "        print(images_details)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "def extract_boxes(text_content):\n",
    "    return re.findall(r'(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+)', text_content)\n",
    "\n",
    "def process_image(img_path, txt_path, base_save_dir):\n",
    "    # Load the image\n",
    "    img = cv2.imread(str(img_path))\n",
    "    \n",
    "    # Read the coordinates from the .txt file\n",
    "    with open(txt_path, 'r') as file:\n",
    "        text_content = file.read()\n",
    "    \n",
    "    # Extract boxes from the content\n",
    "    boxes = extract_boxes(text_content)\n",
    "    # print(boxes)\n",
    "    \n",
    "    # Create a save directory for this image based on its name\n",
    "    save_dir = base_save_dir / img_path.stem\n",
    "    save_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    images_details = {}\n",
    "    \n",
    "    for idx, box in enumerate(boxes):\n",
    "        x_coords = [int(box[i]) for i in range(0, 8, 2)]\n",
    "        y_coords = [int(box[i]) for i in range(1, 8, 2)]\n",
    "        \n",
    "        min_x, max_x = min(x_coords), max(x_coords)\n",
    "        min_y, max_y = min(y_coords), max(y_coords)\n",
    "        \n",
    "        width = max_x - min_x\n",
    "        height = max_y - min_y\n",
    "        \n",
    "        cropped_img = img[min_y:max_y, min_x:max_x]\n",
    "        img_name = f'text_{idx}.jpg'\n",
    "        \n",
    "        # Save the cropped image in the new directory\n",
    "        cv2.imwrite(str(save_dir / img_name), cropped_img)\n",
    "        \n",
    "        images_details[img_name] = {'x': min_x, 'y': min_y, 'w': width, 'h': height}\n",
    "    \n",
    "    return images_details\n",
    "\n",
    "# Directory paths\n",
    "img_dir = Path('/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/')\n",
    "base_save_dir = Path('/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/crop_craft/')\n",
    "\n",
    "# Process each image and its corresponding text file\n",
    "for img_path in img_dir.glob('*.jpg'):\n",
    "    txt_path = img_dir / f'res_{img_path.stem}.txt'\n",
    "    if txt_path.exists():\n",
    "        print(f'Processing {img_path.name}...')\n",
    "        images_details = process_image(img_path, txt_path, base_save_dir)\n",
    "        print(images_details)\n"
   ],
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "# Function to extract the bounding box information\n",
    "def extract_boxes(text_content):\n",
    "    # Extract lines using regex to match the numerical patterns\n",
    "    return re.findall(r'(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+),(\\d+)', text_content)\n",
    "\n",
    "# Load the image where we want to extract the boxes\n",
    "# img_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.jpg'\n",
    "img_path = '/home/eslab/osh/CapStone/data/더 단백 커피.png'\n",
    "img = cv2.imread(img_path)\n",
    "\n",
    "# Read the coordinates from the uploaded .txt file\n",
    "txt_path = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/res_더 단백 커피.txt'\n",
    "with open(txt_path, 'r') as file:\n",
    "    text_content = file.read()\n",
    "\n",
    "# Call the function to extract boxes from the content\n",
    "boxes = extract_boxes(text_content)\n",
    "\n",
    "# Directory to save cropped images\n",
    "save_dir = '/home/eslab/osh/CapStone/OCR/CRAFT-pytorch/result/crop_craft/'\n",
    "\n",
    "# Ensure the save directory exists\n",
    "Path(save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Initialize dictionary to store image details\n",
    "images_details = {}\n",
    "\n",
    "# Cropping and saving each image based on the bounding box\n",
    "for idx, box in enumerate(boxes):\n",
    "    x_coords = [int(box[i]) for i in range(0, 8, 2)]\n",
    "    # print('x_coords : ', x_coords)\n",
    "    y_coords = [int(box[i]) for i in range(1, 8, 2)]\n",
    "    # print('y_coords : ', y_coords)\n",
    "    \n",
    "    # Extract the minimum and maximum coordinates\n",
    "    min_x, max_x = min(x_coords), max(x_coords)\n",
    "    min_y, max_y = min(y_coords), max(y_coords)\n",
    "    \n",
    "    # Define width and height of the box\n",
    "    width = max_x - min_x\n",
    "    height = max_y - min_y\n",
    "    \n",
    "    # Crop the image\n",
    "    cropped_img = img[min_y:max_y, min_x:max_x]\n",
    "    \n",
    "    # Define the file name for the cropped image\n",
    "    img_name = f'text_{idx}.jpg'\n",
    "    \n",
    "    # Save the cropped image\n",
    "    cv2.imwrite(save_dir + img_name, cropped_img)\n",
    "    \n",
    "    # Store details in the dictionary\n",
    "    images_details[img_name] = {'x': min_x, 'y': min_y, 'w': width, 'h': height}\n",
    "    \n",
    "# Return the dictionary with image details\n",
    "images_details"
   ],
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nyh38",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
